{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 64) ## input, output 784 = 28 * 28\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10) # 10 classification classes\n",
    "    \n",
    "    def forward(self, x):\n",
    "        a1 = F.relu(self.fc1(x)) #!!!!\n",
    "        a2 = F.relu(self.fc2(a1))\n",
    "        a3 = F.relu(self.fc3(a2))\n",
    "        z4 = self.fc4(a3)\n",
    "        return F.log_softmax(z4, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1380, 0.4158, 0.7474, 0.9336, 0.4602, 0.3996, 0.1077, 0.3190, 0.8540,\n",
       "         0.2864, 0.6968, 0.2436, 0.2148, 0.7647, 0.7617, 0.8035, 0.0325, 0.1286,\n",
       "         0.0891, 0.4869, 0.6352, 0.5246, 0.1644, 0.5060, 0.3051, 0.3056, 0.2613,\n",
       "         0.4045],\n",
       "        [0.3453, 0.3369, 0.0485, 0.7268, 0.2928, 0.7089, 0.3089, 0.8582, 0.2381,\n",
       "         0.0183, 0.6306, 0.2338, 0.5357, 0.3949, 0.8479, 0.8893, 0.9465, 0.8866,\n",
       "         0.8665, 0.7828, 0.1166, 0.7046, 0.0526, 0.1207, 0.6251, 0.7034, 0.1955,\n",
       "         0.3271],\n",
       "        [0.2377, 0.0583, 0.3186, 0.2782, 0.0495, 0.4361, 0.0655, 0.5960, 0.9042,\n",
       "         0.1195, 0.2156, 0.3752, 0.3583, 0.7951, 0.5920, 0.8448, 0.7836, 0.1000,\n",
       "         0.6633, 0.0931, 0.9109, 0.7277, 0.6949, 0.5217, 0.6469, 0.1868, 0.2743,\n",
       "         0.6424],\n",
       "        [0.9771, 0.4885, 0.1296, 0.3138, 0.7648, 0.7053, 0.1580, 0.3518, 0.5829,\n",
       "         0.4970, 0.4014, 0.2827, 0.3136, 0.9917, 0.1978, 0.4587, 0.5708, 0.7133,\n",
       "         0.8980, 0.9469, 0.6566, 0.0794, 0.9849, 0.1639, 0.8428, 0.4574, 0.3855,\n",
       "         0.1195],\n",
       "        [0.8306, 0.4201, 0.6671, 0.4454, 0.5365, 0.3542, 0.7658, 0.3395, 0.0890,\n",
       "         0.3091, 0.4335, 0.3736, 0.7691, 0.4494, 0.6046, 0.9263, 0.0684, 0.8189,\n",
       "         0.0091, 0.3989, 0.9522, 0.0899, 0.1229, 0.4399, 0.6190, 0.8607, 0.1360,\n",
       "         0.4576],\n",
       "        [0.6355, 0.6330, 0.0579, 0.9757, 0.5366, 0.2453, 0.4513, 0.1726, 0.2231,\n",
       "         0.0043, 0.6915, 0.8545, 0.9440, 0.3853, 0.6430, 0.9785, 0.4534, 0.8617,\n",
       "         0.6142, 0.5685, 0.0908, 0.0348, 0.2300, 0.0361, 0.7297, 0.2684, 0.2602,\n",
       "         0.9756],\n",
       "        [0.6480, 0.3672, 0.5174, 0.6898, 0.8171, 0.2088, 0.2120, 0.4691, 0.7198,\n",
       "         0.0125, 0.9740, 0.8444, 0.4616, 0.9490, 0.8072, 0.8221, 0.8943, 0.4091,\n",
       "         0.3811, 0.9552, 0.5161, 0.4641, 0.6576, 0.1109, 0.5255, 0.2319, 0.5171,\n",
       "         0.0432],\n",
       "        [0.5137, 0.8481, 0.5010, 0.3148, 0.9244, 0.5341, 0.7419, 0.6851, 0.5679,\n",
       "         0.3810, 0.0850, 0.7604, 0.4147, 0.3770, 0.2051, 0.4986, 0.7907, 0.3502,\n",
       "         0.4046, 0.7637, 0.9059, 0.2045, 0.4287, 0.1097, 0.8134, 0.2069, 0.6696,\n",
       "         0.1155],\n",
       "        [0.2374, 0.3458, 0.0637, 0.4370, 0.3704, 0.3231, 0.9129, 0.9120, 0.9172,\n",
       "         0.5527, 0.8561, 0.4741, 0.7495, 0.2552, 0.8884, 0.3780, 0.3226, 0.6112,\n",
       "         0.7779, 0.7813, 0.4883, 0.8515, 0.9936, 0.5743, 0.8877, 0.1774, 0.0594,\n",
       "         0.1147],\n",
       "        [0.2336, 0.7635, 0.1978, 0.5559, 0.9362, 0.2724, 0.6006, 0.3756, 0.1851,\n",
       "         0.1817, 0.9707, 0.5296, 0.3355, 0.0772, 0.1219, 0.1094, 0.7902, 0.3232,\n",
       "         0.6640, 0.6364, 0.6314, 0.4344, 0.7115, 0.1081, 0.6390, 0.5149, 0.8144,\n",
       "         0.8429],\n",
       "        [0.6429, 0.6556, 0.3709, 0.1645, 0.4037, 0.7899, 0.1159, 0.5401, 0.7328,\n",
       "         0.1829, 0.9235, 0.6077, 0.1680, 0.6496, 0.1343, 0.4022, 0.0529, 0.3223,\n",
       "         0.1742, 0.5853, 0.0684, 0.8339, 0.1909, 0.3852, 0.4744, 0.2786, 0.0321,\n",
       "         0.9608],\n",
       "        [0.2402, 0.6608, 0.8449, 0.9350, 0.6209, 0.5521, 0.4560, 0.3870, 0.5947,\n",
       "         0.3593, 0.3893, 0.8392, 0.9206, 0.5588, 0.7597, 0.9747, 0.7646, 0.1780,\n",
       "         0.6491, 0.7026, 0.0178, 0.2826, 0.0825, 0.9868, 0.1276, 0.7579, 0.9028,\n",
       "         0.1802],\n",
       "        [0.6476, 0.2944, 0.0076, 0.0127, 0.6171, 0.5174, 0.6193, 0.0868, 0.9253,\n",
       "         0.7160, 0.3568, 0.2778, 0.7852, 0.0175, 0.1748, 0.7559, 0.6267, 0.3019,\n",
       "         0.5808, 0.2627, 0.8352, 0.3823, 0.9753, 0.2245, 0.3355, 0.5541, 0.8486,\n",
       "         0.2280],\n",
       "        [0.1726, 0.6262, 0.2660, 0.8601, 0.4351, 0.5455, 0.6310, 0.1605, 0.6569,\n",
       "         0.5119, 0.2888, 0.3035, 0.4655, 0.4886, 0.4394, 0.5822, 0.2529, 0.3512,\n",
       "         0.9987, 0.6615, 0.4086, 0.6136, 0.2319, 0.7988, 0.1687, 0.9079, 0.4400,\n",
       "         0.3844],\n",
       "        [0.8981, 0.7227, 0.1629, 0.6191, 0.6358, 0.2091, 0.4141, 0.5236, 0.9094,\n",
       "         0.1189, 0.6536, 0.3891, 0.8828, 0.6283, 0.6508, 0.1568, 0.6640, 0.1905,\n",
       "         0.6551, 0.5743, 0.7234, 0.0189, 0.2529, 0.8505, 0.7349, 0.7096, 0.9209,\n",
       "         0.6763],\n",
       "        [0.7391, 0.6591, 0.1614, 0.2860, 0.0616, 0.3101, 0.6186, 0.0509, 0.1247,\n",
       "         0.6782, 0.4248, 0.8712, 0.3597, 0.4855, 0.9422, 0.1498, 0.1932, 0.6177,\n",
       "         0.0965, 0.0427, 0.7291, 0.6747, 0.3330, 0.0643, 0.1848, 0.2452, 0.9168,\n",
       "         0.3273],\n",
       "        [0.1894, 0.9677, 0.3891, 0.4789, 0.6823, 0.5666, 0.2947, 0.1691, 0.1704,\n",
       "         0.9413, 0.4497, 0.6760, 0.0175, 0.0586, 0.5033, 0.2684, 0.9821, 0.8602,\n",
       "         0.8566, 0.6505, 0.0572, 0.3947, 0.9327, 0.0185, 0.8573, 0.7451, 0.3436,\n",
       "         0.0727],\n",
       "        [0.7576, 0.7524, 0.4936, 0.4989, 0.0013, 0.3689, 0.1628, 0.5249, 0.2262,\n",
       "         0.3252, 0.8054, 0.2200, 0.0571, 0.1323, 0.8598, 0.6482, 0.7584, 0.0416,\n",
       "         0.0944, 0.9767, 0.9894, 0.1823, 0.6071, 0.1686, 0.4233, 0.7500, 0.9743,\n",
       "         0.4819],\n",
       "        [0.8266, 0.7482, 0.0025, 0.6859, 0.1888, 0.8893, 0.6638, 0.5589, 0.4120,\n",
       "         0.8731, 0.1955, 0.3851, 0.5941, 0.0742, 0.0066, 0.2367, 0.6718, 0.9855,\n",
       "         0.1015, 0.3518, 0.5439, 0.4554, 0.5428, 0.7139, 0.4429, 0.2234, 0.2056,\n",
       "         0.0619],\n",
       "        [0.6391, 0.4134, 0.6328, 0.6811, 0.7789, 0.7704, 0.3682, 0.9183, 0.5288,\n",
       "         0.3298, 0.4556, 0.6042, 0.9789, 0.6990, 0.8446, 0.7047, 0.2717, 0.7733,\n",
       "         0.8535, 0.1881, 0.1148, 0.7219, 0.1516, 0.6287, 0.7943, 0.7991, 0.0753,\n",
       "         0.7194],\n",
       "        [0.2000, 0.6988, 0.7975, 0.9594, 0.4833, 0.9528, 0.6416, 0.0243, 0.2996,\n",
       "         0.1541, 0.6540, 0.2586, 0.2694, 0.5751, 0.4114, 0.3496, 0.2949, 0.2783,\n",
       "         0.1697, 0.0320, 0.0551, 0.4362, 0.1192, 0.1623, 0.7927, 0.2740, 0.3203,\n",
       "         0.2685],\n",
       "        [0.4160, 0.4932, 0.6125, 0.8958, 0.8472, 0.2022, 0.2082, 0.6964, 0.0871,\n",
       "         0.2818, 0.4960, 0.4878, 0.9451, 0.3109, 0.0079, 0.5434, 0.7377, 0.8357,\n",
       "         0.6721, 0.0247, 0.8404, 0.4816, 0.2178, 0.0988, 0.6043, 0.6866, 0.6159,\n",
       "         0.2310],\n",
       "        [0.1643, 0.9607, 0.5997, 0.4856, 0.5837, 0.4860, 0.7326, 0.4827, 0.8271,\n",
       "         0.1496, 0.2893, 0.3018, 0.1362, 0.7472, 0.6550, 0.1571, 0.0612, 0.3212,\n",
       "         0.7898, 0.0039, 0.8539, 0.6217, 0.5537, 0.1612, 0.6148, 0.4385, 0.7569,\n",
       "         0.9932],\n",
       "        [0.1999, 0.4039, 0.7191, 0.9475, 0.1440, 0.6215, 0.3200, 0.4067, 0.7933,\n",
       "         0.9600, 0.7633, 0.0887, 0.3986, 0.2714, 0.1562, 0.1944, 0.1602, 0.6003,\n",
       "         0.3203, 0.8076, 0.2918, 0.8355, 0.5079, 0.2979, 0.6732, 0.3735, 0.6102,\n",
       "         0.4011],\n",
       "        [0.6908, 0.5384, 0.4289, 0.1822, 0.8271, 0.7136, 0.3144, 0.0796, 0.5557,\n",
       "         0.8818, 0.0806, 0.8846, 0.3221, 0.0496, 0.8769, 0.0069, 0.3262, 0.3848,\n",
       "         0.8288, 0.7109, 0.4535, 0.0454, 0.3792, 0.4851, 0.5243, 0.0783, 0.2918,\n",
       "         0.2718],\n",
       "        [0.4795, 0.8673, 0.4196, 0.7544, 0.8830, 0.8187, 0.3916, 0.1228, 0.4747,\n",
       "         0.5190, 0.1598, 0.7246, 0.2669, 0.7013, 0.7510, 0.7272, 0.2340, 0.3495,\n",
       "         0.1074, 0.0635, 0.6035, 0.9108, 0.0131, 0.9302, 0.1421, 0.4423, 0.2101,\n",
       "         0.4513],\n",
       "        [0.3077, 0.1725, 0.2357, 0.4400, 0.1681, 0.8543, 0.0230, 0.3827, 0.3597,\n",
       "         0.8977, 0.8127, 0.7151, 0.1897, 0.6733, 0.7595, 0.6809, 0.1331, 0.4040,\n",
       "         0.3692, 0.6794, 0.6418, 0.4481, 0.9748, 0.6251, 0.4866, 0.5219, 0.2967,\n",
       "         0.5243],\n",
       "        [0.2448, 0.7889, 0.1576, 0.7471, 0.6267, 0.9588, 0.9679, 0.4929, 0.5447,\n",
       "         0.1945, 0.0388, 0.6339, 0.7103, 0.8167, 0.2482, 0.5928, 0.3754, 0.2622,\n",
       "         0.4926, 0.5272, 0.9340, 0.2435, 0.3096, 0.5312, 0.6405, 0.2981, 0.8760,\n",
       "         0.8455]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand((28, 28))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.4685, -2.3375, -2.3180, -2.3418, -2.2545, -2.3114, -2.2547, -2.2338,\n",
      "         -2.3210, -2.2086]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = net(X.view([-1,784])) ## -1 for the number of training examples\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
